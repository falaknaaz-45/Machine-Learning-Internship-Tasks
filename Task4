
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from scipy.stats import randint


url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)


cols_to_drop = ['deck', 'embark_town', 'alive']
existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]
df.drop(existing_cols_to_drop, axis=1, inplace=True)
df.dropna(inplace=True)


def get_who(row):
    if row['Sex'] == 'male' and row['Age'] >= 16:
        return 'man'
    elif row['Sex'] == 'female' and row['Age'] >= 16:
        return 'woman'
    else:
        return 'child'

df['who'] = df.apply(get_who, axis=1)


df['Alone'] = ((df['SibSp'] == 0) & (df['Parch'] == 0)).astype(int)


df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})
df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})
df['Pclass'] = df['Pclass'].map({3: 3, 2: 2, 1: 1})
df['who'] = df['who'].map({'man': 0, 'woman': 1, 'child': 2})

X = df.drop(['Survived', 'Name', 'Ticket', 'Cabin'], axis=1)
y = df['Survived']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


default_model = DecisionTreeClassifier(random_state=42)
default_model.fit(X_train, y_train)
default_preds = default_model.predict(X_test)
default_acc = accuracy_score(y_test, default_preds)
print("ğŸ”¹ Default Accuracy:", default_acc)


param_grid = {
    'max_depth': [3, 5, 7, 9, None],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}

grid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
grid.fit(X_train, y_train)
grid_preds = grid.predict(X_test)
grid_acc = accuracy_score(y_test, grid_preds)

print("\nğŸ”¹ Grid Search Accuracy:", grid_acc)
print("ğŸ”¸ Best Grid Parameters:", grid.best_params_)


param_dist = {
    'max_depth': randint(2, 20),
    'min_samples_split': randint(2, 15),
    'criterion': ['gini', 'entropy']
}

random_search = RandomizedSearchCV(DecisionTreeClassifier(random_state=42),
                                   param_distributions=param_dist,
                                   n_iter=10,
                                   cv=5,
                                   scoring='accuracy',
                                   random_state=42)
random_search.fit(X_train, y_train)
random_preds = random_search.predict(X_test)
random_acc = accuracy_score(y_test, random_preds)

print("\nğŸ”¹ Randomized Search Accuracy:", random_acc)
print("ğŸ”¸ Best Randomized Parameters:", random_search.best_params_)


print("\nğŸ“ˆ --- Performance Summary ---")
print(f"Default Accuracy       : {default_acc:.4f}")
print(f"Grid Search Accuracy   : {grid_acc:.4f}")
print(f"Random Search Accuracy : {random_acc:.4f}")


cm = confusion_matrix(y_test, grid_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid.classes_)
disp.plot(cmap="Blues")
disp.ax_.set_title("ğŸ” Confusion Matrix - Grid Search Model")
plt.show()


importances = grid.best_estimator_.feature_importances_
feature_names = X.columns

plt.figure(figsize=(10, 6))
plt.barh(feature_names, importances, color='teal')
plt.xlabel("Importance Score")
plt.title("ğŸŒŸ Feature Importance - Decision Tree (Grid Search)")
plt.gca().invert_yaxis()
plt.grid(True)
plt.tight_layout()
plt.show()
